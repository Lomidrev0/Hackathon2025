from fastapi import FastAPI, Query
import psycopg2
from psycopg2.extras import RealDictCursor
from langchain_ollama import OllamaEmbeddings, OllamaLLM
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter
import re
import os
import pickle
from fastapi.middleware.cors import CORSMiddleware


# -------------------------------
# âš™ï¸ 1. KonfigurÃ¡cia DB
# -------------------------------
DB_SERVER = "localhost"
DB_USER = "receipts_user"
DB_PASSWORD = "mypassword"
DB_NAME = "receiptsdb"
PORT = 15432


# -------------------------------
# âš™ï¸ 2. InicializÃ¡cia aplikÃ¡cie
# -------------------------------
app = FastAPI(title="Receipts Vector AI Backend (with SQL fallback + training)")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],  # no trailing slash!
    allow_credentials=True,
    allow_methods=["*"],  # allow GET, POST, etc.
    allow_headers=["*"],  # allow all custom headers
)
# -------------------------------
# ğŸ§  3. Pripojenie k DB
# -------------------------------
def fetch_all_receipts():
    conn = psycopg2.connect(
        host=DB_SERVER,
        database=DB_NAME,
        user=DB_USER,
        password=DB_PASSWORD,
        port=PORT
    )
    cursor = conn.cursor(cursor_factory=RealDictCursor)
    cursor.execute("SELECT * FROM item;")
    records = cursor.fetchall()
    cursor.close()
    conn.close()
    return records


# -------------------------------
# ğŸ”¢ 4. Modely a ukladanie indexu
# -------------------------------
embeddings = OllamaEmbeddings(model="mxbai-embed-large")
llm = OllamaLLM(model="llama3:instruct")

VECTOR_DIR = "vector_index"
os.makedirs(VECTOR_DIR, exist_ok=True)
FAISS_PATH = os.path.join(VECTOR_DIR, "receipts_index.faiss")
META_PATH = os.path.join(VECTOR_DIR, "receipts_meta.pkl")

vector_store = None


# -------------------------------
# ğŸš€ 5. Endpoint: vektorizÃ¡cia a uloÅ¾enie
# -------------------------------
@app.get("/ai/vectorize")
async def vectorize_db():
    global vector_store
    records = fetch_all_receipts()
    if not records:
        return {"message": "DatabÃ¡za je prÃ¡zdna."}

    documents = []
    for r in records:
        text = " | ".join([f"{k}: {v}" for k, v in r.items()])
        documents.append(Document(page_content=text))

    # vytvor FAISS index a uloÅ¾ ho
    vector_store = FAISS.from_documents(documents, embeddings)
    vector_store.save_local(FAISS_PATH)

    with open(META_PATH, "wb") as f:
        pickle.dump({"count": len(documents)}, f)

    return {"message": f"NaindexovanÃ½ch {len(documents)} zÃ¡znamov z databÃ¡zy."}


# -------------------------------
# âš™ï¸ 6. PomocnÃ¡ funkcia pre SQL
# -------------------------------
def run_sql_query(sql: str):
    """BezpeÄnÃ© vykonanie SQL dotazu (len SELECT)."""
    if not sql.strip().lower().startswith("select"):
        return {"error": "PovolenÃ© sÃº len SELECT dotazy!"}
    try:
        conn = psycopg2.connect(
            host=DB_SERVER, database=DB_NAME,
            user=DB_USER, password=DB_PASSWORD, port=PORT
        )
        cursor = conn.cursor(cursor_factory=RealDictCursor)
        cursor.execute(sql)
        records = cursor.fetchall()
        cursor.close()
        conn.close()
        return {"result": records}
    except Exception as e:
        return {"error": str(e)}


# -------------------------------
# ğŸ§® 7. Endpoint: AI SQL analytik
# -------------------------------
@app.get("/ai/sql")
async def ai_sql(prompt: str = Query(..., description="OtÃ¡zka, ktorÃº AI prevedie na SQL dotaz")):
    """
    1ï¸âƒ£ AI vygeneruje SQL dotaz z otÃ¡zky pouÅ¾Ã­vateÄ¾a.
    2ï¸âƒ£ SQL sa spustÃ­ na PostgreSQL.
    3ï¸âƒ£ VÃ½sledok sa vrÃ¡ti ako odpoveÄ.
    """
    # PokÃºsime sa vygenerovaÅ¥ SQL dotaz
    system_prompt = """
Si vysoko presnÃ½, logicky uvaÅ¾ujÃºci SQL analytik a dÃ¡tovÃ½ asistent pre PostgreSQL.
Tvojou Ãºlohou je analyzovaÅ¥ otÃ¡zky pouÅ¾Ã­vateÄ¾a (v slovenÄine alebo angliÄtine) a prekladaÅ¥ ich 
do presnÃ½ch, optimalizovanÃ½ch SQL SELECT dotazov. VieÅ¡ tieÅ¾ odhaliÅ¥ kontext alebo vzorce sprÃ¡vania 
na zÃ¡klade Ãºdajov v databÃ¡ze (napr. nÃ¡kupy detskÃ½ch produktov, krmiva, hygieny, domÃ¡cnosti, alkoholu, atÄ.).

ğŸ“Š DatabÃ¡za obsahuje tabuÄ¾ku "item" so stÄºpcami:
- id (integer)
- transaction_id (integer)
- quantity (float)
- name (text)
- price (float)
- ai_name_without_brand_and_quantity (text)
- ai_name_in_english_without_brand_and_quantity (text)
- ai_brand (text)
- ai_category (text)
- ai_quantity_value (float)
- ai_quantity_unit (text)

---

âš™ï¸ HLAVNÃ‰ PRAVIDLÃ:

1. Generuj vÃ½hradne SQL SELECT dotazy vhodnÃ© pre PostgreSQL.
2. Nikdy nepridÃ¡vaj komentÃ¡re ani texty navyÅ¡e â€“ vÃ½sledok musÃ­ byÅ¥ ÄistÃ½ SQL dotaz ukonÄenÃ½ bodkoÄiarkou.
3. VÅ¾dy pouÅ¾Ã­vaj aliasy pre prehÄ¾adnosÅ¥ (napr. `AS total_spent`, `AS avg_price`).
4. PouÅ¾Ã­vaj len existujÃºce stÄºpce. Å½iadne â€œvymyslenÃ©â€ polia.
5. PouÅ¾Ã­vaj funkcie:
   - COUNT(*) â€“ pre poÄet
   - SUM(price) alebo SUM(quantity) â€“ pre celkovÃ© mnoÅ¾stvÃ¡
   - AVG(price) â€“ pre priemer
   - ORDER BY ... LIMIT ... â€“ pre najdrahÅ¡Ã­/najlacnejÅ¡Ã­/najÄastejÅ¡Ã­
   - GROUP BY â€“ pre kategÃ³rie, znaÄky, typy
6. Pre textovÃ© filtre pouÅ¾Ã­vaj `ILIKE` a hÄ¾adaj aj synonymÃ¡ (napr. â€beerâ€œ ~ â€pivoâ€œ, â€babyâ€œ ~ â€childâ€œ, â€dog foodâ€œ ~ â€krmivo pre psaâ€œ).
7. Ak otÃ¡zka obsahuje obdobie (â€za poslednÃ½ rokâ€œ, â€minulÃ½ mesiacâ€œ, â€last weekâ€œ):
   - Ak neexistuje stÄºpec dÃ¡tumu, pouÅ¾i `transaction_id` ako poradovÃ½ indikÃ¡tor, napr.:
     `WHERE transaction_id > (SELECT MAX(transaction_id) - 1000 FROM item)`
   - NepouÅ¾Ã­vaj Å¾iadne timestamp nÃ¡sobenia ani CURRENT_DATE * integer.
8. Ak otÃ¡zka obsahuje mnoÅ¾stvÃ¡, pouÅ¾ij `quantity`, `ai_quantity_value` a podÄ¾a potreby `ai_quantity_unit`.
9. Ak sÃº jednotky zmieÅ¡anÃ© (ml, l, kg, ks), prepoÄÃ­taj ich na jednotnÃº zÃ¡kladnÃº formu (napr. 1000 ml = 1 l).
10. Ak otÃ¡zka obsahuje â€œnajviac kupovanÃ©â€, â€œtop produktyâ€, â€œnajvÃ¤ÄÅ¡Ã­ vÃ½davokâ€, pouÅ¾ij GROUP BY a ORDER BY DESC.

---

ğŸ§  KONCEPTUÃLNE ROZÅ ÃRENIE (behaviorÃ¡lna inteligencia):

Okrem SQL vÃ½stupu mÃ¡Å¡ chÃ¡paÅ¥ aj vÃ½znam dÃ¡t. Ak otÃ¡zka pouÅ¾Ã­vateÄ¾a alebo zistenÃ© Ãºdaje naznaÄujÃº Å¡pecifickÃ© Å¾ivotnÃ© vzorce,
mÃ´Å¾eÅ¡ ich vyhodnotiÅ¥ logicky a neutrÃ¡lne pomenovaÅ¥, napr.:

- Ak sa v Ãºdajoch Äasto objavujÃº produkty ako â€œplienkyâ€, â€œdetskÃ© utierkyâ€, â€œSunarâ€, â€œkaÅ¡iÄkaâ€, kategÃ³rie â€œbabyâ€, â€œchildâ€ â†’ PouÅ¾Ã­vateÄ¾ pravdepodobne mÃ¡ dieÅ¥a ğŸ‘¶.
- Ak sa objavujÃº produkty â€œgranuleâ€, â€œkrmivoâ€, â€œdog foodâ€, â€œcat foodâ€, â€œlitterâ€ â†’ PouÅ¾Ã­vateÄ¾ pravdepodobne mÃ¡ domÃ¡ce zviera ğŸ¶ğŸ±.
- Ak sa opakovane vyskytuje â€œbeerâ€, â€œwineâ€, â€œvodkaâ€, â€œalcoholâ€ â†’ PouÅ¾Ã­vateÄ¾ Äasto nakupuje alkohol ğŸº.
- Ak sa objavujÃº produkty ako â€œÅ¡ampÃ³nâ€, â€œtoaletnÃ½ papierâ€, â€œÄistiace prostriedkyâ€, â€œjarâ€ â†’ ide o domÃ¡ce potreby ğŸ§½.
- Ak sa vyskytujÃº produkty â€œvegetablesâ€, â€œmeatâ€, â€œmilkâ€, â€œeggsâ€, â€œbreadâ€ â†’ ide o potraviny ğŸ.

Tieto informÃ¡cie mÃ´Å¾eÅ¡ pouÅ¾iÅ¥ pre kontextovÃº odpoveÄ, ak sa pouÅ¾Ã­vateÄ¾ pÃ½ta na sprÃ¡vanie, preferencie alebo profil typu:
- â€œMÃ¡m dieÅ¥a?â€
- â€œMÃ¡m psa?â€
- â€œKupujem Äasto alkohol?â€
- â€œNa Äo najviac mÃ­Åˆam?â€

V takom prÃ­pade:
- Analyzuj nÃ¡kupy podÄ¾a relevantnÃ½ch kategÃ³riÃ­ a znaÄiek.
- Ak sÃº jednoznaÄnÃ© dÃ´kazy (napr. existujÃº poloÅ¾ky s `ai_category ILIKE '%baby%'` alebo `ai_name_in_english_without_brand_and_quantity ILIKE '%dog%'`), odpovedz racionÃ¡lne typu:
  - â€PodÄ¾a tvojich nÃ¡kupov to vyzerÃ¡, Å¾e kupujeÅ¡ produkty pre dieÅ¥a ğŸ‘¶.â€œ
  - â€VyzerÃ¡ to, Å¾e Äasto nakupujeÅ¡ produkty pre psa ğŸ¶.â€œ
  - â€Z dÃ¡t vyplÃ½va, Å¾e Äasto kupujeÅ¡ alkoholickÃ© produkty ğŸº.â€œ

---

ğŸ“ˆ PRÃKLADY SPRÃVNYCH DOTAZOV:

- SELECT COUNT(*) AS total_items FROM item;
- SELECT ai_category, SUM(price) AS total_spent FROM item GROUP BY ai_category ORDER BY total_spent DESC;
- SELECT ai_brand, SUM(price) AS total_sales FROM item GROUP BY ai_brand ORDER BY total_sales DESC LIMIT 5;
- SELECT name, SUM(quantity) AS total_liters FROM item WHERE ai_name_in_english_without_brand_and_quantity ILIKE '%beer%' GROUP BY name;
- SELECT COUNT(*) FROM item WHERE ai_name_in_english_without_brand_and_quantity ILIKE '%dog%' OR ai_category ILIKE '%pet%';
- SELECT COUNT(*) FROM item WHERE ai_name_in_english_without_brand_and_quantity ILIKE '%baby%' OR ai_category ILIKE '%child%';

---

ğŸ§± ZHRNUTIE:
- Si extrÃ©mne presnÃ½ a racionÃ¡lny.
- Tvoje vÃ½stupy musia byÅ¥ vÅ¾dy ÄistÃ©, validnÃ© a logicky konzistentnÃ© SQL SELECT dotazy.
- NehalucinujeÅ¡, nepÃ­Å¡eÅ¡ komentÃ¡re ani text navyÅ¡e.
- VieÅ¡ rozpoznaÅ¥ sprÃ¡vanie pouÅ¾Ã­vateÄ¾a na zÃ¡klade nÃ¡kupov a logicky ho interpretovaÅ¥.
- Tvoj cieÄ¾: daÅ¥ pravdivÃº, dÃ¡tovo podloÅ¾enÃº odpoveÄ â€“ Äi ide o ÄÃ­sla, kategÃ³rie, alebo Å¾ivotnÃ© zvyky.
"""


    full_prompt = f"{system_prompt}\nOtÃ¡zka pouÅ¾Ã­vateÄ¾a: {prompt}\nSQL dotaz:"
    sql_query = llm.invoke(full_prompt).strip()

    # BezpeÄnostnÃ¡ kontrola
    if not sql_query.lower().startswith("select"):
        return {"error": "AI nevygenerovala SELECT dotaz.", "sql": sql_query}

    # Spusti SQL
    sql_result = run_sql_query(sql_query)

    return {
        "question": prompt,
        "generated_sql": sql_query,
        "result": sql_result
    }


# -------------------------------
# ğŸ§¬ 8. Endpoint: trÃ©ning (rozÅ¡Ã­renie indexu)
# -------------------------------
@app.get("/ai/train")
async def train_vector_model():
    """
    PokroÄilÃ½ trÃ©ning â€“ rozdelÃ­ texty z DB na menÅ¡ie kÃºsky a vytvorÃ­ robustnejÅ¡Ã­ FAISS index.
    Ide o formu "RAG trÃ©ningu", nie o klasickÃ½ fine-tuning modelu.
    """
    global vector_store
    records = fetch_all_receipts()
    if not records:
        return {"message": "DatabÃ¡za je prÃ¡zdna."}

    documents = []
    for r in records:
        text = " | ".join([f"{k}: {v}" for k, v in r.items()])
        documents.append(Document(page_content=text))

    # rozdelenie textov na menÅ¡ie kÃºsky
    splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=50)
    split_docs = splitter.split_documents(documents)

    vector_store = FAISS.from_documents(split_docs, embeddings)
    vector_store.save_local(FAISS_PATH)

    with open(META_PATH, "wb") as f:
        pickle.dump({"chunks": len(split_docs)}, f)

    return {"message": f"Model natrÃ©novanÃ½ s {len(split_docs)} Äasticami (RAG index)."}


# -------------------------------
# ğŸ§­ 9. Endpoint: AI otÃ¡zky s SQL fallbackom
# -------------------------------
@app.get("/ai/ask")
async def ask_ai(prompt: str = Query(..., description="OtÃ¡zka pre AI")):
    global vector_store

    if re.search(r"(koÄ¾ko|sum|spolu|celkovÃ¡|total|sumu|suma)", prompt.lower()):
        if re.search(r"(pivo|beer)", prompt.lower()):
            conn = psycopg2.connect(
                host=DB_SERVER, database=DB_NAME,
                user=DB_USER, password=DB_PASSWORD, port=PORT
            )
            cursor = conn.cursor()
            cursor.execute("""
                SELECT SUM(price) FROM item
                WHERE name ILIKE '%pivo%' OR ai_name_in_english_without_brand_and_quantity ILIKE '%beer%';
            """)
            total = cursor.fetchone()[0]
            cursor.close()
            conn.close()

            if total:
                return {"question": prompt, "answer": f"Spolu si minul {total:.2f} â‚¬ na pivÃ¡ ğŸº."}
            else:
                return {"question": prompt, "answer": "V databÃ¡ze som nenaÅ¡iel Å¾iadne pivÃ¡."}

    if vector_store is None:
        try:
            vector_store = FAISS.load_local(FAISS_PATH, embeddings, allow_dangerous_deserialization=True)
        except Exception:
            return {"error": "VektorovÃ½ index neexistuje. NajskÃ´r spusti /ai/vectorize alebo /ai/train."}

    results = vector_store.similarity_search(prompt, k=20)
    if not results:
        return {"answer": "NenaÅ¡li sa Å¾iadne relevantnÃ© vÃ½sledky."}

    def clean_context(documents):
        cleaned = []
        for d in documents:
            text = re.sub(r'\s*\|\s*', ', ', d.page_content)
            cleaned.append(text)
        return "\n".join(cleaned)

    context = clean_context(results)

    full_prompt = f"""
    Si inteligentnÃ½ analytickÃ½ asistent. Na zÃ¡klade Ãºdajov z databÃ¡zy odpovedz na otÃ¡zku pouÅ¾Ã­vateÄ¾a.
    KaÅ¾dÃ½ riadok obsahuje:
    - nÃ¡zov produktu (name)
    - cenu (price)
    - kategÃ³riu (ai_category)
    - znaÄku (ai_brand)

    Tu sÃº najrelevantnejÅ¡ie dÃ¡ta:
    {context}

    Odpovedz vÃ½hradne na zÃ¡klade Ãºdajov vyÅ¡Å¡ie.
    BuÄ presnÃ½, odpovedz maximÃ¡lne v 2 vetÃ¡ch.
    OtÃ¡zka pouÅ¾Ã­vateÄ¾a: {prompt}
    """

    answer = llm.invoke(full_prompt)

    return {
        "question": prompt,
        "answer": answer.strip(),
        "context_used": len(results)
    }


# -------------------------------
# ğŸ  10. Root endpoint
# -------------------------------
@app.get("/")
async def root():
    return {"message": "Vector AI backend (LLaMA3 + SQL fallback + trÃ©ning) beÅ¾Ã­ ğŸš€"}
